{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18d7b48",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8ff379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455bb336",
   "metadata": {},
   "source": [
    "# 2. Dataset validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bb751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Number of duplicated records: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv (r'C:\\Users\\juand\\OneDrive\\Escritorio\\TripleTen\\Project 9\\Megaline-EDA-Predictive-Modeling\\Dataset\\users_behavior.csv')\n",
    "#df = pd.read_csv (r'C:\\Users\\valen\\OneDrive\\Escritorio\\Juano_VS\\Megaline-EDA-Predictive-Modeling\\Dataset\\users_behavior.csv')\n",
    "print (df.info())\n",
    "print ()\n",
    "print (df.head())\n",
    "print ()\n",
    "print ('Number of duplicated records:', sum(df.duplicated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346dc6f",
   "metadata": {},
   "source": [
    "# 3. Data segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf81154",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop ('is_ultra', axis=1)\n",
    "y = df['is_ultra']\n",
    "x_train, x_test, y_train, y_test = train_test_split (X, y, test_size = 0.75, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e38b0",
   "metadata": {},
   "source": [
    "# 4. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02cd397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model in the validation set has a depth of: 8 with a score of: 0.7942762339278308\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for i in range (1, 21): \n",
    "    tree = DecisionTreeClassifier (random_state=12345, max_depth=i)\n",
    "    tree.fit (x_train, y_train)\n",
    "    score = tree.score (x_test, y_test)\n",
    "    if score > best_score: \n",
    "        best_score = score\n",
    "        best_depth = i\n",
    "print ('Best model in the validation set has a depth of:', best_depth, 'with a score of:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd8a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the best model in the validation set (n_estimators=54): 0.7946909995852344\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "best_score = 0\n",
    "best_estimator = 0\n",
    "for est in range (1, 101): \n",
    "    forest = RandomForestClassifier (random_state=12345, n_estimators=est)\n",
    "    forest.fit (x_train, y_train)\n",
    "    score = forest.score (x_test, y_test)\n",
    "    if score > best_score: \n",
    "        best_score = score\n",
    "        best_estimator = est\n",
    "print ('The accuracy for the best model in the validation set (n_estimators={}): {}'.format (best_estimator, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd88d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the logistic regression model in the training set was:  0.7409713574097135\n",
      "The accuracy for the logistic regression model in the testing set was:  0.7465781833264206\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "logi = LogisticRegression (random_state = 12345, solver='liblinear')\n",
    "logi.fit (x_train, y_train)\n",
    "score_train = logi.score (x_train, y_train)\n",
    "score_test = logi.score (x_test, y_test)\n",
    "\n",
    "print ('The accuracy for the logistic regression model in the training set was: ', score_train)\n",
    "print ('The accuracy for the logistic regression model in the testing set was: ', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e90b8a",
   "metadata": {},
   "source": [
    "## 4.1. Findings from the Model Quality Investigation\n",
    "\n",
    "During the model evaluation phase, several classification algorithms were tested, including Decision Tree, Logistic Regression, and Random Forest. For each model, different hyperparameters were tuned to identify the configuration with the highest predictive performance.\n",
    "\n",
    "Decision Tree: Tested with varying max_depth values from 1 to 20. The model reached a maximum accuracy of ~0.7942, which met the required threshold but did not outperform the other models.\n",
    "\n",
    "Logistic Regression: Tested using the liblinear solver. However, the model did not meet the 0.75 threshold, achieving an accuracy of ~0.7466 on the test set.\n",
    "\n",
    "Random Forest: Evaluated with n_estimators ranging from 1 to 101. The model showed consistent improvements as the number of trees increased. The best configuration was achieved with 54 estimators, yielding an accuracy of ~0.7947, surpassing the project threshold by 0.0447 points.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Among all tested models, the RandomForestClassifier demonstrated the best performance and generalization ability for predicting Megaline customer plan categories. Hyperparameter tuning confirmed that increasing the number of estimators significantly improved accuracy up to the optimal value found at n_estimators = 54."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c236c1",
   "metadata": {},
   "source": [
    "## 4.2. Final Model Evaluation on the Test Set\n",
    "After selecting the RandomForestClassifier with 54 estimators as the best-performing model during the hyperparameter tuning phase, the final step is to evaluate its performance on the test set, which contains data unseen during both training and model selection. This evaluation provides an unbiased estimate of the model’s ability to generalize to new customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536c42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy score of the best model (Random Forest) on the test set is: 0.7947\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier (random_state=12345, n_estimators=54)\n",
    "best_model.fit (x_train, y_train)\n",
    "predictions = best_model.predict (x_test)\n",
    "score = accuracy_score (y_test, predictions)\n",
    "\n",
    "print(f\"The final accuracy score of the best model (Random Forest) on the test set is: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdcbc9",
   "metadata": {},
   "source": [
    "Final Result\n",
    "\n",
    "The selected RandomForestClassifier achieved a final test accuracy of ≈0.7947, confirming that it generalizes well to unseen data and successfully meets the project threshold of 0.75. This result validates the model as a reliable solution for predicting Megaline customer plan categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b2f4",
   "metadata": {},
   "source": [
    "# 5. Sanity check¶\n",
    "Sanity check was performed to verify that the RandomForestClassifier is actually learning meaningful patterns rather than predicting at random.\n",
    "\n",
    "First, the class distribution of the target variable was inspected:\n",
    "\n",
    "## 5.1. Verify classes balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdc5135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    0.665006\n",
       "1    0.334994\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts (normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768336d7",
   "metadata": {},
   "source": [
    "## 5.2. Conclusion\n",
    "The class distribution revealed that the most frequent class represents approximately 66% of the data.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "A random classifier would be expected to achieve around 50% accuracy.\n",
    "\n",
    "A trivial classifier that always predicts the majority class would achieve approximately 66% accuracy.\n",
    "\n",
    "For comparison:\n",
    "\n",
    "Model\tExpected Accuracy\n",
    "Random guessing\t~0.50\n",
    "Majority-class predictor\t~0.66\n",
    "Final Random Forest model\t~0.7947\n",
    "These results confirm that the model significantly outperforms both a random baseline and a trivial majority-class classifier. Therefore, it has learned meaningful patterns from the data and successfully passes the sanity check."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mega",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
